MVM Config:--------------
Bit Stream:  2
Bit Slice:  4
ADC Bit:  7
Xbar size:  128 128
Real ADC Characteristics:  True ideal
Xbar Weight Std Gamma 0.0
WARNING: crossbar sizes with different row annd column dimension not supported.
MVM Config:--------------
Bit Stream:  2
Bit Slice:  4
ADC Bit:  7
Xbar size:  128 128
Real ADC Characteristics:  True ideal
Xbar Weight Std Gamma 0.0
WARNING: crossbar sizes with different row annd column dimension not supported.
Available models:
resnet20_adc resnet110 resnet1202 resnet20 resnet32 resnet44 resnet56 resnet8 resnet20_mvm
Loading pretrained model from  saved_models/resnet20_qwa_nobias_1_12Aug.th
Pretrained model training accuracy: 93.05
-Starting retraining on mvm model, fp model weights will be quantized. Check args.rt
All pretrained parameters loaded successfully
Files already downloaded and verified
Test before retraining:
Test: [0/79]	Time 25.771 (25.771)	Loss 1.2516 (1.2516)	Prec@1 64.062 (64.062)
Test: [60/79]	Time 21.508 (21.593)	Loss 1.1171 (1.3252)	Prec@1 71.094 (63.102)
 * Prec@1 62.730
Test Accuracy:62.73
Retraining:
current lr 1.00000e-04
Epoch: [0][0/391]	Time 22.123 (22.123)	Data 0.181 (0.181)	Loss 0.4251 (0.4251)	Prec@1 83.594 (83.594)
Epoch: [0][60/391]	Time 21.497 (21.511)	Data 0.000 (0.003)	Loss 0.3908 (0.4182)	Prec@1 85.156 (85.733)
Epoch: [0][120/391]	Time 21.492 (21.502)	Data 0.000 (0.002)	Loss 0.4221 (0.4065)	Prec@1 86.719 (86.209)
Epoch: [0][180/391]	Time 21.446 (21.501)	Data 0.000 (0.001)	Loss 0.4520 (0.3951)	Prec@1 82.031 (86.477)
Epoch: [0][240/391]	Time 21.479 (21.502)	Data 0.000 (0.001)	Loss 0.4155 (0.3889)	Prec@1 86.719 (86.634)
Epoch: [0][300/391]	Time 21.559 (21.503)	Data 0.000 (0.001)	Loss 0.4407 (0.3823)	Prec@1 85.156 (86.856)
Epoch: [0][360/391]	Time 21.461 (21.503)	Data 0.000 (0.001)	Loss 0.2917 (0.3791)	Prec@1 89.844 (86.944)
Test: [0/79]	Time 21.624 (21.624)	Loss 0.2493 (0.2493)	Prec@1 89.062 (89.062)
Test: [60/79]	Time 21.441 (21.499)	Loss 0.2658 (0.3086)	Prec@1 91.406 (89.972)
 * Prec@1 89.870
Best Accuracy:89.87
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-04
Epoch: [1][0/391]	Time 21.664 (21.664)	Data 0.149 (0.149)	Loss 0.3812 (0.3812)	Prec@1 84.375 (84.375)
Epoch: [1][60/391]	Time 21.559 (21.510)	Data 0.000 (0.003)	Loss 0.4704 (0.3679)	Prec@1 86.719 (86.872)
Epoch: [1][120/391]	Time 21.549 (21.509)	Data 0.000 (0.001)	Loss 0.3569 (0.3550)	Prec@1 87.500 (87.403)
Epoch: [1][180/391]	Time 21.576 (21.506)	Data 0.000 (0.001)	Loss 0.2826 (0.3539)	Prec@1 88.281 (87.535)
Epoch: [1][240/391]	Time 21.474 (21.504)	Data 0.000 (0.001)	Loss 0.4214 (0.3534)	Prec@1 86.719 (87.600)
Epoch: [1][300/391]	Time 21.448 (21.504)	Data 0.000 (0.001)	Loss 0.3397 (0.3550)	Prec@1 87.500 (87.583)
Epoch: [1][360/391]	Time 21.454 (21.504)	Data 0.000 (0.001)	Loss 0.3394 (0.3518)	Prec@1 87.500 (87.790)
Test: [0/79]	Time 21.669 (21.669)	Loss 0.2530 (0.2530)	Prec@1 89.844 (89.844)
Test: [60/79]	Time 21.510 (21.494)	Loss 0.3459 (0.3117)	Prec@1 88.281 (89.972)
 * Prec@1 90.060
Best Accuracy:90.06
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-04
Epoch: [2][0/391]	Time 21.755 (21.755)	Data 0.167 (0.167)	Loss 0.2587 (0.2587)	Prec@1 91.406 (91.406)
Epoch: [2][60/391]	Time 21.553 (21.505)	Data 0.000 (0.003)	Loss 0.3870 (0.3421)	Prec@1 89.844 (88.102)
Epoch: [2][120/391]	Time 21.567 (21.503)	Data 0.000 (0.002)	Loss 0.2971 (0.3415)	Prec@1 89.062 (87.862)
Epoch: [2][180/391]	Time 21.490 (21.502)	Data 0.000 (0.001)	Loss 0.2568 (0.3390)	Prec@1 91.406 (88.027)
Epoch: [2][240/391]	Time 21.452 (21.502)	Data 0.000 (0.001)	Loss 0.1897 (0.3418)	Prec@1 91.406 (87.908)
Epoch: [2][300/391]	Time 21.189 (21.132)	Data 0.000 (0.001)	Loss 0.2727 (0.3409)	Prec@1 90.625 (87.988)
Epoch: [2][360/391]	Time 21.136 (21.142)	Data 0.000 (0.001)	Loss 0.4574 (0.3409)	Prec@1 85.156 (88.022)
Test: [0/79]	Time 21.340 (21.340)	Loss 0.2369 (0.2369)	Prec@1 91.406 (91.406)
Test: [60/79]	Time 21.201 (21.178)	Loss 0.3063 (0.3071)	Prec@1 89.844 (90.074)
 * Prec@1 90.110
Best Accuracy:90.11
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-04
Epoch: [3][0/391]	Time 21.339 (21.339)	Data 0.159 (0.159)	Loss 0.1477 (0.1477)	Prec@1 96.875 (96.875)
Epoch: [3][60/391]	Time 21.168 (21.193)	Data 0.000 (0.003)	Loss 0.3238 (0.3299)	Prec@1 86.719 (88.256)
Epoch: [3][120/391]	Time 21.162 (21.196)	Data 0.000 (0.002)	Loss 0.3735 (0.3339)	Prec@1 86.719 (88.423)
Epoch: [3][180/391]	Time 21.130 (21.194)	Data 0.000 (0.001)	Loss 0.3291 (0.3360)	Prec@1 89.062 (88.359)
Epoch: [3][240/391]	Time 21.214 (21.194)	Data 0.000 (0.001)	Loss 0.3921 (0.3404)	Prec@1 87.500 (88.171)
Epoch: [3][300/391]	Time 21.120 (21.193)	Data 0.000 (0.001)	Loss 0.2944 (0.3425)	Prec@1 88.281 (88.159)
Epoch: [3][360/391]	Time 21.446 (21.195)	Data 0.000 (0.001)	Loss 0.2687 (0.3395)	Prec@1 89.844 (88.257)
Test: [0/79]	Time 21.840 (21.840)	Loss 0.1829 (0.1829)	Prec@1 92.969 (92.969)
Test: [60/79]	Time 21.727 (21.733)	Loss 0.2774 (0.3019)	Prec@1 93.750 (90.587)
 * Prec@1 90.560
Best Accuracy:90.56
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-04
Epoch: [4][0/391]	Time 21.936 (21.936)	Data 0.154 (0.154)	Loss 0.2001 (0.2001)	Prec@1 93.750 (93.750)
Epoch: [4][60/391]	Time 21.673 (21.760)	Data 0.000 (0.003)	Loss 0.3050 (0.3340)	Prec@1 87.500 (88.179)
Epoch: [4][120/391]	Time 21.795 (21.756)	Data 0.000 (0.002)	Loss 0.3130 (0.3334)	Prec@1 89.844 (88.404)
Epoch: [4][180/391]	Time 21.759 (21.755)	Data 0.000 (0.001)	Loss 0.2231 (0.3365)	Prec@1 90.625 (88.398)
Epoch: [4][240/391]	Time 21.775 (21.755)	Data 0.000 (0.001)	Loss 0.3488 (0.3324)	Prec@1 89.844 (88.508)
Epoch: [4][300/391]	Time 21.775 (21.758)	Data 0.000 (0.001)	Loss 0.2320 (0.3330)	Prec@1 92.969 (88.466)
Epoch: [4][360/391]	Time 21.757 (21.757)	Data 0.000 (0.001)	Loss 0.2409 (0.3355)	Prec@1 92.188 (88.420)
Test: [0/79]	Time 21.903 (21.903)	Loss 0.2328 (0.2328)	Prec@1 90.625 (90.625)
Test: [60/79]	Time 21.737 (21.727)	Loss 0.2765 (0.2948)	Prec@1 92.188 (90.599)
 * Prec@1 90.440
Best Accuracy:90.56
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-04
Epoch: [5][0/391]	Time 21.958 (21.958)	Data 0.187 (0.187)	Loss 0.3623 (0.3623)	Prec@1 89.062 (89.062)
Epoch: [5][60/391]	Time 21.766 (21.746)	Data 0.000 (0.003)	Loss 0.3171 (0.3265)	Prec@1 88.281 (88.550)
Epoch: [5][120/391]	Time 21.765 (21.747)	Data 0.000 (0.002)	Loss 0.3145 (0.3257)	Prec@1 89.844 (88.559)
Epoch: [5][180/391]	Time 21.689 (21.744)	Data 0.000 (0.001)	Loss 0.3903 (0.3286)	Prec@1 90.625 (88.506)
Epoch: [5][240/391]	Time 21.769 (21.745)	Data 0.000 (0.001)	Loss 0.2883 (0.3302)	Prec@1 91.406 (88.447)
Epoch: [5][300/391]	Time 21.712 (21.744)	Data 0.000 (0.001)	Loss 0.2761 (0.3290)	Prec@1 90.625 (88.491)
Epoch: [5][360/391]	Time 21.783 (21.745)	Data 0.000 (0.001)	Loss 0.3375 (0.3296)	Prec@1 87.500 (88.439)
Test: [0/79]	Time 21.958 (21.958)	Loss 0.2004 (0.2004)	Prec@1 89.844 (89.844)
Test: [60/79]	Time 21.766 (21.740)	Loss 0.2615 (0.3054)	Prec@1 92.969 (90.177)
 * Prec@1 90.140
Best Accuracy:90.56
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-05
Epoch: [6][0/391]	Time 21.805 (21.805)	Data 0.188 (0.188)	Loss 0.3825 (0.3825)	Prec@1 87.500 (87.500)
Epoch: [6][60/391]	Time 21.792 (21.763)	Data 0.000 (0.003)	Loss 0.3138 (0.3190)	Prec@1 86.719 (88.858)
Epoch: [6][120/391]	Time 21.787 (21.753)	Data 0.000 (0.002)	Loss 0.2953 (0.3226)	Prec@1 88.281 (88.669)
Epoch: [6][180/391]	Time 21.747 (21.754)	Data 0.000 (0.001)	Loss 0.3203 (0.3275)	Prec@1 89.062 (88.570)
Epoch: [6][240/391]	Time 21.757 (21.750)	Data 0.000 (0.001)	Loss 0.3794 (0.3293)	Prec@1 85.938 (88.534)
Epoch: [6][300/391]	Time 21.768 (21.753)	Data 0.000 (0.001)	Loss 0.2204 (0.3265)	Prec@1 91.406 (88.611)
Epoch: [6][360/391]	Time 21.780 (21.751)	Data 0.000 (0.001)	Loss 0.4035 (0.3262)	Prec@1 86.719 (88.617)
Test: [0/79]	Time 21.849 (21.849)	Loss 0.2023 (0.2023)	Prec@1 92.969 (92.969)
Test: [60/79]	Time 21.739 (21.732)	Loss 0.2682 (0.2955)	Prec@1 93.750 (90.523)
 * Prec@1 90.320
Best Accuracy:90.56
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-05
Epoch: [7][0/391]	Time 21.979 (21.979)	Data 0.163 (0.163)	Loss 0.2451 (0.2451)	Prec@1 92.188 (92.188)
Epoch: [7][60/391]	Time 21.355 (21.761)	Data 0.000 (0.003)	Loss 0.2041 (0.3153)	Prec@1 92.969 (89.306)
Epoch: [7][120/391]	Time 21.792 (21.755)	Data 0.000 (0.002)	Loss 0.4282 (0.3131)	Prec@1 87.500 (89.243)
Epoch: [7][180/391]	Time 21.771 (21.754)	Data 0.000 (0.001)	Loss 0.4186 (0.3155)	Prec@1 85.938 (89.101)
Epoch: [7][240/391]	Time 21.772 (21.755)	Data 0.000 (0.001)	Loss 0.3371 (0.3189)	Prec@1 89.844 (88.939)
Epoch: [7][300/391]	Time 21.670 (21.754)	Data 0.000 (0.001)	Loss 0.2364 (0.3186)	Prec@1 89.062 (88.873)
Epoch: [7][360/391]	Time 21.733 (21.756)	Data 0.000 (0.001)	Loss 0.3152 (0.3181)	Prec@1 85.156 (88.872)
Test: [0/79]	Time 21.901 (21.901)	Loss 0.2079 (0.2079)	Prec@1 89.844 (89.844)
Test: [60/79]	Time 21.907 (21.755)	Loss 0.2599 (0.3033)	Prec@1 92.969 (90.561)
 * Prec@1 90.450
Best Accuracy:90.56
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-05
Epoch: [8][0/391]	Time 21.930 (21.930)	Data 0.198 (0.198)	Loss 0.3112 (0.3112)	Prec@1 87.500 (87.500)
Epoch: [8][60/391]	Time 21.766 (21.742)	Data 0.000 (0.003)	Loss 0.2330 (0.3178)	Prec@1 92.969 (88.858)
Epoch: [8][120/391]	Time 21.700 (21.745)	Data 0.000 (0.002)	Loss 0.2552 (0.3222)	Prec@1 90.625 (88.914)
Epoch: [8][180/391]	Time 21.770 (21.745)	Data 0.000 (0.001)	Loss 0.3408 (0.3255)	Prec@1 86.719 (88.847)
Epoch: [8][240/391]	Time 21.955 (21.748)	Data 0.000 (0.001)	Loss 0.2593 (0.3254)	Prec@1 90.625 (88.732)
Epoch: [8][300/391]	Time 21.758 (21.747)	Data 0.000 (0.001)	Loss 0.3438 (0.3271)	Prec@1 86.719 (88.697)
Epoch: [8][360/391]	Time 21.788 (21.747)	Data 0.000 (0.001)	Loss 0.3589 (0.3299)	Prec@1 86.719 (88.599)
Test: [0/79]	Time 21.902 (21.902)	Loss 0.1658 (0.1658)	Prec@1 94.531 (94.531)
Test: [60/79]	Time 21.661 (21.740)	Loss 0.2812 (0.2997)	Prec@1 92.969 (90.535)
 * Prec@1 90.440
Best Accuracy:90.56
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-05
Epoch: [9][0/391]	Time 21.905 (21.905)	Data 0.176 (0.176)	Loss 0.2654 (0.2654)	Prec@1 91.406 (91.406)
Epoch: [9][60/391]	Time 21.699 (21.770)	Data 0.000 (0.003)	Loss 0.2820 (0.3252)	Prec@1 90.625 (88.691)
Epoch: [9][120/391]	Time 21.762 (21.764)	Data 0.000 (0.002)	Loss 0.3959 (0.3287)	Prec@1 88.281 (88.533)
Epoch: [9][180/391]	Time 21.757 (21.760)	Data 0.000 (0.001)	Loss 0.4322 (0.3270)	Prec@1 87.500 (88.657)
Epoch: [9][240/391]	Time 21.770 (21.757)	Data 0.000 (0.001)	Loss 0.3463 (0.3282)	Prec@1 88.281 (88.712)
Epoch: [9][300/391]	Time 21.785 (21.759)	Data 0.000 (0.001)	Loss 0.3093 (0.3268)	Prec@1 89.062 (88.668)
Epoch: [9][360/391]	Time 21.702 (21.759)	Data 0.000 (0.001)	Loss 0.4636 (0.3255)	Prec@1 82.812 (88.686)
Test: [0/79]	Time 21.916 (21.916)	Loss 0.1985 (0.1985)	Prec@1 92.188 (92.188)
Test: [60/79]	Time 21.740 (21.739)	Loss 0.2410 (0.2920)	Prec@1 91.406 (90.574)
 * Prec@1 90.620
Best Accuracy:90.62
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-06
Epoch: [10][0/391]	Time 21.909 (21.909)	Data 0.182 (0.182)	Loss 0.3382 (0.3382)	Prec@1 86.719 (86.719)
Epoch: [10][60/391]	Time 21.804 (21.750)	Data 0.000 (0.003)	Loss 0.2466 (0.3280)	Prec@1 89.844 (88.192)
Epoch: [10][120/391]	Time 21.676 (21.749)	Data 0.000 (0.002)	Loss 0.2811 (0.3268)	Prec@1 91.406 (88.501)
Epoch: [10][180/391]	Time 21.757 (21.749)	Data 0.000 (0.001)	Loss 0.3374 (0.3287)	Prec@1 88.281 (88.463)
Epoch: [10][240/391]	Time 21.777 (21.752)	Data 0.000 (0.001)	Loss 0.3064 (0.3233)	Prec@1 89.844 (88.635)
Epoch: [10][300/391]	Time 21.748 (21.749)	Data 0.000 (0.001)	Loss 0.3037 (0.3223)	Prec@1 89.062 (88.689)
Epoch: [10][360/391]	Time 21.753 (21.750)	Data 0.000 (0.001)	Loss 0.3071 (0.3204)	Prec@1 87.500 (88.788)
Test: [0/79]	Time 21.903 (21.903)	Loss 0.2181 (0.2181)	Prec@1 92.188 (92.188)
Test: [60/79]	Time 21.707 (21.738)	Loss 0.2649 (0.3020)	Prec@1 92.969 (90.305)
 * Prec@1 90.380
Best Accuracy:90.62
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-06
Epoch: [11][0/391]	Time 21.919 (21.919)	Data 0.194 (0.194)	Loss 0.3578 (0.3578)	Prec@1 88.281 (88.281)
Epoch: [11][60/391]	Time 21.774 (21.753)	Data 0.000 (0.003)	Loss 0.2086 (0.3285)	Prec@1 93.750 (88.537)
Epoch: [11][120/391]	Time 21.702 (21.748)	Data 0.000 (0.002)	Loss 0.2660 (0.3298)	Prec@1 89.062 (88.443)
Epoch: [11][180/391]	Time 21.750 (21.751)	Data 0.000 (0.001)	Loss 0.3422 (0.3242)	Prec@1 88.281 (88.605)
Epoch: [11][240/391]	Time 21.761 (21.750)	Data 0.000 (0.001)	Loss 0.3616 (0.3267)	Prec@1 89.062 (88.518)
Epoch: [11][300/391]	Time 21.733 (21.749)	Data 0.000 (0.001)	Loss 0.2940 (0.3239)	Prec@1 90.625 (88.681)
Epoch: [11][360/391]	Time 21.703 (21.748)	Data 0.000 (0.001)	Loss 0.2447 (0.3262)	Prec@1 92.188 (88.643)
Test: [0/79]	Time 21.907 (21.907)	Loss 0.2054 (0.2054)	Prec@1 91.406 (91.406)
Test: [60/79]	Time 21.786 (21.739)	Loss 0.2496 (0.2973)	Prec@1 92.188 (90.394)
 * Prec@1 90.420
Best Accuracy:90.62
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-06
Epoch: [12][0/391]	Time 21.952 (21.952)	Data 0.186 (0.186)	Loss 0.3490 (0.3490)	Prec@1 86.719 (86.719)
Epoch: [12][60/391]	Time 21.925 (21.779)	Data 0.000 (0.003)	Loss 0.3539 (0.3324)	Prec@1 87.500 (88.537)
Epoch: [12][120/391]	Time 21.752 (21.770)	Data 0.000 (0.002)	Loss 0.2389 (0.3281)	Prec@1 94.531 (88.946)
Epoch: [12][180/391]	Time 21.764 (21.763)	Data 0.000 (0.001)	Loss 0.3856 (0.3271)	Prec@1 88.281 (88.808)
Epoch: [12][240/391]	Time 21.739 (21.760)	Data 0.000 (0.001)	Loss 0.4788 (0.3286)	Prec@1 85.156 (88.716)
Epoch: [12][300/391]	Time 21.781 (21.757)	Data 0.000 (0.001)	Loss 0.2505 (0.3293)	Prec@1 89.844 (88.608)
Epoch: [12][360/391]	Time 21.775 (21.758)	Data 0.000 (0.001)	Loss 0.3312 (0.3279)	Prec@1 85.156 (88.606)
Test: [0/79]	Time 21.814 (21.814)	Loss 0.1952 (0.1952)	Prec@1 92.969 (92.969)
Test: [60/79]	Time 21.961 (21.740)	Loss 0.2525 (0.2991)	Prec@1 93.750 (90.574)
 * Prec@1 90.450
Best Accuracy:90.62
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-06
Epoch: [13][0/391]	Time 21.989 (21.989)	Data 0.162 (0.162)	Loss 0.2386 (0.2386)	Prec@1 89.062 (89.062)
Epoch: [13][60/391]	Time 21.779 (21.742)	Data 0.000 (0.003)	Loss 0.2978 (0.3237)	Prec@1 88.281 (88.653)
Epoch: [13][120/391]	Time 21.710 (21.740)	Data 0.000 (0.002)	Loss 0.2282 (0.3236)	Prec@1 92.188 (88.837)
Epoch: [13][180/391]	Time 21.737 (21.739)	Data 0.000 (0.001)	Loss 0.3255 (0.3205)	Prec@1 89.062 (88.963)
Epoch: [13][240/391]	Time 21.956 (21.741)	Data 0.000 (0.001)	Loss 0.2423 (0.3211)	Prec@1 90.625 (88.936)
Epoch: [13][300/391]	Time 21.793 (21.743)	Data 0.000 (0.001)	Loss 0.3021 (0.3173)	Prec@1 89.062 (89.029)
Epoch: [13][360/391]	Time 21.764 (21.744)	Data 0.000 (0.001)	Loss 0.3070 (0.3175)	Prec@1 87.500 (89.011)
Test: [0/79]	Time 21.902 (21.902)	Loss 0.2079 (0.2079)	Prec@1 92.188 (92.188)
Test: [60/79]	Time 21.757 (21.733)	Loss 0.2209 (0.2988)	Prec@1 94.531 (90.484)
 * Prec@1 90.630
Best Accuracy:90.63
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-07
Epoch: [14][0/391]	Time 21.990 (21.990)	Data 0.202 (0.202)	Loss 0.2883 (0.2883)	Prec@1 89.844 (89.844)
Epoch: [14][60/391]	Time 21.773 (21.760)	Data 0.000 (0.004)	Loss 0.3748 (0.3247)	Prec@1 87.500 (89.075)
Epoch: [14][120/391]	Time 21.763 (21.750)	Data 0.000 (0.002)	Loss 0.3012 (0.3265)	Prec@1 89.844 (88.701)
Epoch: [14][180/391]	Time 21.719 (21.749)	Data 0.000 (0.001)	Loss 0.4936 (0.3234)	Prec@1 83.594 (88.769)
Epoch: [14][240/391]	Time 21.780 (21.749)	Data 0.000 (0.001)	Loss 0.3543 (0.3231)	Prec@1 86.719 (88.729)
Epoch: [14][300/391]	Time 21.731 (21.747)	Data 0.000 (0.001)	Loss 0.3846 (0.3263)	Prec@1 88.281 (88.632)
Epoch: [14][360/391]	Time 21.761 (21.748)	Data 0.000 (0.001)	Loss 0.3091 (0.3252)	Prec@1 88.281 (88.653)
Test: [0/79]	Time 21.889 (21.889)	Loss 0.1760 (0.1760)	Prec@1 93.750 (93.750)
Test: [60/79]	Time 21.749 (21.733)	Loss 0.2353 (0.2966)	Prec@1 93.750 (90.561)
 * Prec@1 90.490
Best Accuracy:90.63
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-07
Epoch: [15][0/391]	Time 21.920 (21.920)	Data 0.147 (0.147)	Loss 0.3967 (0.3967)	Prec@1 88.281 (88.281)
Epoch: [15][60/391]	Time 21.756 (21.745)	Data 0.000 (0.003)	Loss 0.3836 (0.3273)	Prec@1 87.500 (88.345)
Epoch: [15][120/391]	Time 21.752 (21.747)	Data 0.000 (0.001)	Loss 0.3231 (0.3264)	Prec@1 88.281 (88.643)
Epoch: [15][180/391]	Time 21.785 (21.748)	Data 0.000 (0.001)	Loss 0.3122 (0.3248)	Prec@1 88.281 (88.683)
Epoch: [15][240/391]	Time 21.769 (21.750)	Data 0.000 (0.001)	Loss 0.3624 (0.3214)	Prec@1 89.844 (88.774)
Epoch: [15][300/391]	Time 21.705 (21.748)	Data 0.000 (0.001)	Loss 0.2525 (0.3199)	Prec@1 92.188 (88.878)
Epoch: [15][360/391]	Time 21.766 (21.749)	Data 0.000 (0.001)	Loss 0.3463 (0.3193)	Prec@1 87.500 (88.889)
Test: [0/79]	Time 21.863 (21.863)	Loss 0.1976 (0.1976)	Prec@1 92.969 (92.969)
Test: [60/79]	Time 21.705 (21.733)	Loss 0.2284 (0.2981)	Prec@1 92.969 (90.561)
 * Prec@1 90.460
Best Accuracy:90.63
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-07
Epoch: [16][0/391]	Time 21.932 (21.932)	Data 0.177 (0.177)	Loss 0.3179 (0.3179)	Prec@1 89.844 (89.844)
Epoch: [16][60/391]	Time 21.699 (21.761)	Data 0.000 (0.003)	Loss 0.2082 (0.3067)	Prec@1 92.969 (89.139)
Epoch: [16][120/391]	Time 21.768 (21.752)	Data 0.000 (0.002)	Loss 0.2337 (0.3150)	Prec@1 91.406 (88.740)
Epoch: [16][180/391]	Time 21.661 (21.752)	Data 0.000 (0.001)	Loss 0.4077 (0.3206)	Prec@1 83.594 (88.717)
Epoch: [16][240/391]	Time 21.758 (21.749)	Data 0.000 (0.001)	Loss 0.3311 (0.3211)	Prec@1 91.406 (88.771)
Epoch: [16][300/391]	Time 21.745 (21.748)	Data 0.000 (0.001)	Loss 0.3524 (0.3226)	Prec@1 88.281 (88.715)
Epoch: [16][360/391]	Time 21.677 (21.746)	Data 0.000 (0.001)	Loss 0.4512 (0.3246)	Prec@1 86.719 (88.708)
Test: [0/79]	Time 21.947 (21.947)	Loss 0.2105 (0.2105)	Prec@1 92.188 (92.188)
Test: [60/79]	Time 21.708 (21.739)	Loss 0.2668 (0.2998)	Prec@1 91.406 (90.407)
 * Prec@1 90.410
Best Accuracy:90.63
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-07
Epoch: [17][0/391]	Time 21.953 (21.953)	Data 0.207 (0.207)	Loss 0.2797 (0.2797)	Prec@1 89.062 (89.062)
Epoch: [17][60/391]	Time 21.945 (21.764)	Data 0.000 (0.004)	Loss 0.3377 (0.3236)	Prec@1 85.938 (88.563)
Epoch: [17][120/391]	Time 21.710 (21.754)	Data 0.000 (0.002)	Loss 0.2512 (0.3278)	Prec@1 91.406 (88.436)
Epoch: [17][180/391]	Time 21.750 (21.753)	Data 0.000 (0.001)	Loss 0.3152 (0.3254)	Prec@1 89.062 (88.566)
Epoch: [17][240/391]	Time 21.774 (21.754)	Data 0.000 (0.001)	Loss 0.1502 (0.3256)	Prec@1 94.531 (88.515)
Epoch: [17][300/391]	Time 21.791 (21.753)	Data 0.000 (0.001)	Loss 0.5120 (0.3276)	Prec@1 81.250 (88.434)
Epoch: [17][360/391]	Time 21.756 (21.755)	Data 0.000 (0.001)	Loss 0.3411 (0.3258)	Prec@1 89.062 (88.573)
Test: [0/79]	Time 21.892 (21.892)	Loss 0.1932 (0.1932)	Prec@1 93.750 (93.750)
Test: [60/79]	Time 21.936 (21.739)	Loss 0.2332 (0.2921)	Prec@1 92.188 (90.459)
 * Prec@1 90.460
Best Accuracy:90.63
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-08
Epoch: [18][0/391]	Time 21.928 (21.928)	Data 0.170 (0.170)	Loss 0.3054 (0.3054)	Prec@1 89.844 (89.844)
Epoch: [18][60/391]	Time 21.751 (21.749)	Data 0.000 (0.003)	Loss 0.3429 (0.3083)	Prec@1 88.281 (89.152)
Epoch: [18][120/391]	Time 21.750 (21.755)	Data 0.000 (0.002)	Loss 0.3184 (0.3143)	Prec@1 87.500 (88.959)
Epoch: [18][180/391]	Time 21.238 (21.750)	Data 0.000 (0.001)	Loss 0.2574 (0.3176)	Prec@1 89.062 (88.855)
Epoch: [18][240/391]	Time 21.342 (21.750)	Data 0.000 (0.001)	Loss 0.3454 (0.3158)	Prec@1 87.500 (88.943)
Epoch: [18][300/391]	Time 21.781 (21.754)	Data 0.000 (0.001)	Loss 0.2339 (0.3178)	Prec@1 91.406 (88.933)
Epoch: [18][360/391]	Time 21.736 (21.752)	Data 0.000 (0.001)	Loss 0.3025 (0.3191)	Prec@1 89.062 (88.872)
Test: [0/79]	Time 21.913 (21.913)	Loss 0.1832 (0.1832)	Prec@1 91.406 (91.406)
Test: [60/79]	Time 21.719 (21.736)	Loss 0.2336 (0.3039)	Prec@1 93.750 (90.471)
 * Prec@1 90.440
Best Accuracy:90.63
Saving the trained model as: Nov8_retrain_1.th
current lr 1.00000e-08
Epoch: [19][0/391]	Time 21.994 (21.994)	Data 0.204 (0.204)	Loss 0.2043 (0.2043)	Prec@1 93.750 (93.750)
Epoch: [19][60/391]	Time 21.715 (21.760)	Data 0.000 (0.004)	Loss 0.3090 (0.3154)	Prec@1 89.844 (89.331)
Epoch: [19][120/391]	Time 21.744 (21.756)	Data 0.000 (0.002)	Loss 0.3346 (0.3188)	Prec@1 90.625 (89.095)
Epoch: [19][180/391]	Time 21.772 (21.758)	Data 0.000 (0.001)	Loss 0.3500 (0.3192)	Prec@1 89.062 (89.032)
Epoch: [19][240/391]	Time 21.838 (21.757)	Data 0.000 (0.001)	Loss 0.3386 (0.3211)	Prec@1 89.844 (88.907)
Epoch: [19][300/391]	Time 21.391 (21.758)	Data 0.000 (0.001)	Loss 0.3719 (0.3198)	Prec@1 89.062 (88.865)
Epoch: [19][360/391]	Time 21.810 (21.760)	Data 0.000 (0.001)	Loss 0.3397 (0.3209)	Prec@1 91.406 (88.855)
Test: [0/79]	Time 21.861 (21.861)	Loss 0.2012 (0.2012)	Prec@1 90.625 (90.625)
Test: [60/79]	Time 21.754 (21.744)	Loss 0.2397 (0.3023)	Prec@1 94.531 (90.279)
 * Prec@1 90.380
Best Accuracy:90.63
Saving the trained model as: Nov8_retrain_1.th
