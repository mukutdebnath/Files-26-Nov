MVM Config:--------------
Bit Stream:  2
Bit Slice:  4
ADC Bit:  6
Xbar size:  128 128
Real ADC Characteristics:  True ideal
Xbar Weight Std Gamma 0.0
WARNING: crossbar sizes with different row annd column dimension not supported.
MVM Config:--------------
Bit Stream:  2
Bit Slice:  4
ADC Bit:  6
Xbar size:  128 128
Real ADC Characteristics:  True ideal
Xbar Weight Std Gamma 0.0
WARNING: crossbar sizes with different row annd column dimension not supported.
Available models:
resnet20_adc resnet110 resnet1202 resnet20 resnet32 resnet44 resnet56 resnet8 resnet20_mvm
Loading pretrained model from  saved_models/resnet20_qwa_nobias_1_12Aug.th
Pretrained model training accuracy: 93.05
-Starting retraining on mvm model, fp model weights will be quantized. Check args.rt
All pretrained parameters loaded successfully
Files already downloaded and verified
Test before retraining:
Test: [0/79]	Time 7.658 (7.658)	Loss 3.1721 (3.1721)	Prec@1 14.844 (14.844)
Test: [60/79]	Time 6.019 (6.059)	Loss 3.2732 (3.3082)	Prec@1 21.875 (17.610)
 * Prec@1 17.670
Test Accuracy:17.67
Retraining:
current lr 1.00000e-04
Epoch: [0][0/391]	Time 6.500 (6.500)	Data 0.171 (0.171)	Loss 1.2054 (1.2054)	Prec@1 61.719 (61.719)
Epoch: [0][60/391]	Time 5.976 (6.040)	Data 0.000 (0.003)	Loss 0.8128 (0.8466)	Prec@1 73.438 (73.181)
Epoch: [0][120/391]	Time 6.059 (6.038)	Data 0.000 (0.002)	Loss 0.7544 (0.8151)	Prec@1 77.344 (73.902)
Epoch: [0][180/391]	Time 6.053 (6.043)	Data 0.000 (0.001)	Loss 0.9422 (0.7975)	Prec@1 68.750 (74.616)
Epoch: [0][240/391]	Time 6.052 (6.044)	Data 0.000 (0.001)	Loss 0.8695 (0.7953)	Prec@1 70.312 (74.520)
Epoch: [0][300/391]	Time 6.070 (6.042)	Data 0.000 (0.001)	Loss 0.9165 (0.7907)	Prec@1 73.438 (74.642)
Epoch: [0][360/391]	Time 6.036 (6.041)	Data 0.000 (0.001)	Loss 0.7365 (0.7871)	Prec@1 76.562 (74.662)
Test: [0/79]	Time 6.134 (6.134)	Loss 0.6405 (0.6405)	Prec@1 78.906 (78.906)
Test: [60/79]	Time 6.019 (5.990)	Loss 0.5896 (0.6731)	Prec@1 81.250 (78.663)
 * Prec@1 78.760
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-04
Epoch: [1][0/391]	Time 6.296 (6.296)	Data 0.229 (0.229)	Loss 0.8558 (0.8558)	Prec@1 71.094 (71.094)
Epoch: [1][60/391]	Time 6.079 (6.047)	Data 0.000 (0.004)	Loss 0.7567 (0.7844)	Prec@1 75.000 (75.000)
Epoch: [1][120/391]	Time 6.075 (6.044)	Data 0.000 (0.002)	Loss 0.7417 (0.7824)	Prec@1 77.344 (74.677)
Epoch: [1][180/391]	Time 6.020 (6.042)	Data 0.000 (0.002)	Loss 0.7441 (0.7893)	Prec@1 79.688 (74.361)
Epoch: [1][240/391]	Time 6.005 (6.044)	Data 0.000 (0.001)	Loss 0.7897 (0.7989)	Prec@1 78.906 (73.911)
Epoch: [1][300/391]	Time 6.055 (6.045)	Data 0.000 (0.001)	Loss 0.8272 (0.8040)	Prec@1 75.000 (73.757)
Epoch: [1][360/391]	Time 5.995 (6.047)	Data 0.000 (0.001)	Loss 0.7557 (0.8128)	Prec@1 71.094 (73.494)
Test: [0/79]	Time 6.127 (6.127)	Loss 0.7581 (0.7581)	Prec@1 75.781 (75.781)
Test: [60/79]	Time 6.011 (5.997)	Loss 0.7927 (0.7667)	Prec@1 82.812 (75.807)
 * Prec@1 75.830
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-04
Epoch: [2][0/391]	Time 6.224 (6.224)	Data 0.171 (0.171)	Loss 0.7726 (0.7726)	Prec@1 74.219 (74.219)
Epoch: [2][60/391]	Time 6.042 (6.018)	Data 0.001 (0.003)	Loss 0.8857 (0.8868)	Prec@1 71.875 (70.991)
Epoch: [2][120/391]	Time 5.960 (6.013)	Data 0.000 (0.002)	Loss 0.8974 (0.8951)	Prec@1 67.969 (70.952)
Epoch: [2][180/391]	Time 5.954 (6.015)	Data 0.000 (0.001)	Loss 0.8490 (0.9055)	Prec@1 71.094 (70.779)
Epoch: [2][240/391]	Time 6.003 (6.014)	Data 0.000 (0.001)	Loss 0.8809 (0.9321)	Prec@1 75.781 (69.674)
Epoch: [2][300/391]	Time 6.004 (6.015)	Data 0.000 (0.001)	Loss 1.0477 (0.9608)	Prec@1 68.750 (68.594)
Epoch: [2][360/391]	Time 6.089 (6.016)	Data 0.000 (0.001)	Loss 1.6164 (1.0159)	Prec@1 46.875 (66.753)
Test: [0/79]	Time 6.109 (6.109)	Loss 3.0278 (3.0278)	Prec@1 34.375 (34.375)
Test: [60/79]	Time 5.981 (5.996)	Loss 2.7841 (2.8123)	Prec@1 39.844 (37.167)
 * Prec@1 36.930
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-04
Epoch: [3][0/391]	Time 6.247 (6.247)	Data 0.225 (0.225)	Loss 2.1388 (2.1388)	Prec@1 38.281 (38.281)
Epoch: [3][60/391]	Time 6.007 (6.003)	Data 0.000 (0.004)	Loss 2.3026 (3.6832)	Prec@1 11.719 (18.058)
Epoch: [3][120/391]	Time 6.043 (6.010)	Data 0.000 (0.002)	Loss 2.3026 (2.9986)	Prec@1 10.938 (14.043)
Epoch: [3][180/391]	Time 5.995 (6.011)	Data 0.000 (0.001)	Loss 2.3026 (2.7679)	Prec@1 10.938 (12.629)
Epoch: [3][240/391]	Time 6.052 (6.013)	Data 0.000 (0.001)	Loss 2.3026 (2.6520)	Prec@1 11.719 (11.920)
Epoch: [3][300/391]	Time 6.039 (6.012)	Data 0.000 (0.001)	Loss 2.3026 (2.5824)	Prec@1 7.812 (11.540)
Epoch: [3][360/391]	Time 6.044 (6.013)	Data 0.000 (0.001)	Loss 2.3026 (2.5359)	Prec@1 7.031 (11.344)
Test: [0/79]	Time 6.073 (6.073)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.969 (5.991)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-04
Epoch: [4][0/391]	Time 6.164 (6.164)	Data 0.206 (0.206)	Loss 2.3026 (2.3026)	Prec@1 8.594 (8.594)
Epoch: [4][60/391]	Time 5.983 (5.965)	Data 0.000 (0.004)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.131)
Epoch: [4][120/391]	Time 5.959 (5.962)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 7.031 (10.027)
Epoch: [4][180/391]	Time 5.928 (5.963)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.009)
Epoch: [4][240/391]	Time 5.963 (5.966)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (10.036)
Epoch: [4][300/391]	Time 6.057 (5.969)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 6.250 (10.013)
Epoch: [4][360/391]	Time 5.989 (5.968)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 6.250 (9.942)
Test: [0/79]	Time 6.205 (6.205)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.988 (5.976)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-04
Epoch: [5][0/391]	Time 6.254 (6.254)	Data 0.174 (0.174)	Loss 2.3026 (2.3026)	Prec@1 9.375 (9.375)
Epoch: [5][60/391]	Time 5.995 (6.028)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 6.250 (9.887)
Epoch: [5][120/391]	Time 6.042 (6.030)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 5.469 (9.975)
Epoch: [5][180/391]	Time 6.153 (6.025)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 14.844 (9.820)
Epoch: [5][240/391]	Time 6.057 (6.022)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.812 (9.965)
Epoch: [5][300/391]	Time 6.037 (6.022)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.084)
Epoch: [5][360/391]	Time 6.048 (6.021)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.050)
Test: [0/79]	Time 6.096 (6.096)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 6.010 (5.974)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-05
Epoch: [6][0/391]	Time 6.163 (6.163)	Data 0.180 (0.180)	Loss 2.3026 (2.3026)	Prec@1 10.938 (10.938)
Epoch: [6][60/391]	Time 6.033 (6.025)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.118)
Epoch: [6][120/391]	Time 5.942 (6.022)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 12.500 (9.691)
Epoch: [6][180/391]	Time 5.975 (6.017)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.910)
Epoch: [6][240/391]	Time 5.969 (6.015)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (9.887)
Epoch: [6][300/391]	Time 5.980 (6.014)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (9.902)
Epoch: [6][360/391]	Time 6.029 (6.013)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.812 (9.923)
Test: [0/79]	Time 6.222 (6.222)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.941 (5.983)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-05
Epoch: [7][0/391]	Time 6.246 (6.246)	Data 0.203 (0.203)	Loss 2.3026 (2.3026)	Prec@1 10.938 (10.938)
Epoch: [7][60/391]	Time 6.005 (5.998)	Data 0.000 (0.004)	Loss 2.3026 (2.3026)	Prec@1 7.031 (9.426)
Epoch: [7][120/391]	Time 6.021 (5.999)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 12.500 (9.627)
Epoch: [7][180/391]	Time 6.005 (5.999)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.707)
Epoch: [7][240/391]	Time 6.039 (5.999)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.812 (9.790)
Epoch: [7][300/391]	Time 6.135 (6.001)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.812 (9.881)
Epoch: [7][360/391]	Time 6.034 (6.002)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.953)
Test: [0/79]	Time 6.128 (6.128)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.931 (5.963)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-05
Epoch: [8][0/391]	Time 6.213 (6.213)	Data 0.198 (0.198)	Loss 2.3026 (2.3026)	Prec@1 9.375 (9.375)
Epoch: [8][60/391]	Time 5.963 (5.995)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 13.281 (10.540)
Epoch: [8][120/391]	Time 6.039 (5.995)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.369)
Epoch: [8][180/391]	Time 5.999 (5.998)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.083)
Epoch: [8][240/391]	Time 5.946 (5.998)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 13.281 (9.900)
Epoch: [8][300/391]	Time 6.048 (5.998)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.013)
Epoch: [8][360/391]	Time 6.031 (5.997)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.972)
Test: [0/79]	Time 6.133 (6.133)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.916 (5.987)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-05
Epoch: [9][0/391]	Time 6.286 (6.286)	Data 0.188 (0.188)	Loss 2.3026 (2.3026)	Prec@1 11.719 (11.719)
Epoch: [9][60/391]	Time 5.958 (6.004)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 6.250 (10.412)
Epoch: [9][120/391]	Time 6.040 (6.015)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 11.719 (9.859)
Epoch: [9][180/391]	Time 5.978 (6.012)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 12.500 (10.057)
Epoch: [9][240/391]	Time 6.008 (6.010)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.978)
Epoch: [9][300/391]	Time 6.063 (6.013)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (9.993)
Epoch: [9][360/391]	Time 6.141 (6.014)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.005)
Test: [0/79]	Time 6.083 (6.083)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.925 (5.976)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-06
Epoch: [10][0/391]	Time 6.207 (6.207)	Data 0.200 (0.200)	Loss 2.3026 (2.3026)	Prec@1 14.062 (14.062)
Epoch: [10][60/391]	Time 6.029 (6.031)	Data 0.000 (0.004)	Loss 2.3026 (2.3026)	Prec@1 12.500 (9.670)
Epoch: [10][120/391]	Time 6.069 (6.035)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 10.156 (9.821)
Epoch: [10][180/391]	Time 6.004 (6.040)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.733)
Epoch: [10][240/391]	Time 5.956 (6.040)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.031 (9.813)
Epoch: [10][300/391]	Time 5.997 (6.039)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.812 (9.873)
Epoch: [10][360/391]	Time 6.048 (6.039)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (9.907)
Test: [0/79]	Time 6.198 (6.198)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.962 (5.968)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-06
Epoch: [11][0/391]	Time 6.192 (6.192)	Data 0.179 (0.179)	Loss 2.3026 (2.3026)	Prec@1 11.719 (11.719)
Epoch: [11][60/391]	Time 5.941 (6.012)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.028)
Epoch: [11][120/391]	Time 5.992 (6.016)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.072)
Epoch: [11][180/391]	Time 6.053 (6.018)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.178)
Epoch: [11][240/391]	Time 6.032 (6.017)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 13.281 (10.059)
Epoch: [11][300/391]	Time 6.016 (6.020)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.026)
Epoch: [11][360/391]	Time 6.012 (6.020)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.005)
Test: [0/79]	Time 6.135 (6.135)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.959 (5.959)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-06
Epoch: [12][0/391]	Time 6.293 (6.293)	Data 0.188 (0.188)	Loss 2.3026 (2.3026)	Prec@1 14.844 (14.844)
Epoch: [12][60/391]	Time 6.003 (6.005)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.336)
Epoch: [12][120/391]	Time 5.989 (6.005)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 7.812 (10.221)
Epoch: [12][180/391]	Time 5.941 (6.001)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 14.844 (10.247)
Epoch: [12][240/391]	Time 6.041 (5.996)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 5.469 (10.049)
Epoch: [12][300/391]	Time 5.939 (5.993)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.021)
Epoch: [12][360/391]	Time 5.973 (5.992)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.035)
Test: [0/79]	Time 6.228 (6.228)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.942 (5.952)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-06
Epoch: [13][0/391]	Time 6.172 (6.172)	Data 0.164 (0.164)	Loss 2.3026 (2.3026)	Prec@1 8.594 (8.594)
Epoch: [13][60/391]	Time 6.033 (6.038)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.412)
Epoch: [13][120/391]	Time 5.948 (6.028)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 7.031 (10.150)
Epoch: [13][180/391]	Time 6.020 (6.026)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.264)
Epoch: [13][240/391]	Time 6.017 (6.026)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 12.500 (10.159)
Epoch: [13][300/391]	Time 6.020 (6.025)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.031 (10.190)
Epoch: [13][360/391]	Time 5.982 (6.025)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.046)
Test: [0/79]	Time 6.207 (6.207)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.948 (5.976)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-07
Epoch: [14][0/391]	Time 6.138 (6.138)	Data 0.169 (0.169)	Loss 2.3026 (2.3026)	Prec@1 14.844 (14.844)
Epoch: [14][60/391]	Time 5.998 (5.980)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.797)
Epoch: [14][120/391]	Time 5.963 (5.984)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 8.594 (10.350)
Epoch: [14][180/391]	Time 5.935 (5.982)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.104)
Epoch: [14][240/391]	Time 6.006 (5.979)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 6.250 (10.020)
Epoch: [14][300/391]	Time 5.998 (5.980)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 6.250 (9.967)
Epoch: [14][360/391]	Time 5.938 (5.982)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.020)
Test: [0/79]	Time 6.114 (6.114)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 6.032 (6.016)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-07
Epoch: [15][0/391]	Time 6.110 (6.110)	Data 0.155 (0.155)	Loss 2.3026 (2.3026)	Prec@1 8.594 (8.594)
Epoch: [15][60/391]	Time 6.036 (6.005)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 7.031 (9.516)
Epoch: [15][120/391]	Time 6.011 (6.006)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.685)
Epoch: [15][180/391]	Time 5.997 (6.002)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.156 (9.863)
Epoch: [15][240/391]	Time 6.008 (6.000)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 9.375 (9.745)
Epoch: [15][300/391]	Time 5.944 (6.000)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (9.977)
Epoch: [15][360/391]	Time 6.043 (5.999)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 13.281 (10.026)
Test: [0/79]	Time 6.107 (6.107)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.918 (5.952)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-07
Epoch: [16][0/391]	Time 6.220 (6.220)	Data 0.220 (0.220)	Loss 2.3026 (2.3026)	Prec@1 6.250 (6.250)
Epoch: [16][60/391]	Time 5.986 (6.054)	Data 0.000 (0.004)	Loss 2.3026 (2.3026)	Prec@1 8.594 (10.105)
Epoch: [16][120/391]	Time 6.025 (6.043)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 9.375 (9.872)
Epoch: [16][180/391]	Time 6.092 (6.037)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.031 (9.850)
Epoch: [16][240/391]	Time 5.989 (6.037)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.020)
Epoch: [16][300/391]	Time 5.946 (6.037)	Data 0.001 (0.001)	Loss 2.3026 (2.3026)	Prec@1 6.250 (10.089)
Epoch: [16][360/391]	Time 6.042 (6.035)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.085)
Test: [0/79]	Time 6.119 (6.119)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.970 (5.981)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-07
Epoch: [17][0/391]	Time 6.193 (6.193)	Data 0.222 (0.222)	Loss 2.3026 (2.3026)	Prec@1 7.812 (7.812)
Epoch: [17][60/391]	Time 5.948 (6.005)	Data 0.000 (0.004)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.195)
Epoch: [17][120/391]	Time 5.979 (6.006)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 11.719 (10.111)
Epoch: [17][180/391]	Time 5.998 (6.008)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.812 (9.997)
Epoch: [17][240/391]	Time 5.985 (6.009)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (10.049)
Epoch: [17][300/391]	Time 5.979 (6.009)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.967)
Epoch: [17][360/391]	Time 6.045 (6.008)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 8.594 (10.035)
Test: [0/79]	Time 6.181 (6.181)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 5.999 (5.990)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-08
Epoch: [18][0/391]	Time 6.183 (6.183)	Data 0.185 (0.185)	Loss 2.3026 (2.3026)	Prec@1 10.938 (10.938)
Epoch: [18][60/391]	Time 5.966 (5.984)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.092)
Epoch: [18][120/391]	Time 6.126 (5.988)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 7.031 (9.982)
Epoch: [18][180/391]	Time 5.970 (5.986)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (9.798)
Epoch: [18][240/391]	Time 5.958 (5.986)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 13.281 (10.007)
Epoch: [18][300/391]	Time 5.991 (5.988)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (9.982)
Epoch: [18][360/391]	Time 5.960 (5.988)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 10.938 (10.003)
Test: [0/79]	Time 6.191 (6.191)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 6.005 (5.954)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
current lr 1.00000e-08
Epoch: [19][0/391]	Time 6.191 (6.191)	Data 0.186 (0.186)	Loss 2.3026 (2.3026)	Prec@1 6.250 (6.250)
Epoch: [19][60/391]	Time 5.964 (6.006)	Data 0.000 (0.003)	Loss 2.3026 (2.3026)	Prec@1 8.594 (9.990)
Epoch: [19][120/391]	Time 5.994 (6.001)	Data 0.000 (0.002)	Loss 2.3026 (2.3026)	Prec@1 7.031 (9.924)
Epoch: [19][180/391]	Time 5.964 (6.004)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 9.375 (10.104)
Epoch: [19][240/391]	Time 5.940 (6.005)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 11.719 (9.968)
Epoch: [19][300/391]	Time 5.966 (5.997)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 7.812 (9.980)
Epoch: [19][360/391]	Time 5.948 (5.994)	Data 0.000 (0.001)	Loss 2.3026 (2.3026)	Prec@1 6.250 (10.003)
Test: [0/79]	Time 6.071 (6.071)	Loss 2.3026 (2.3026)	Prec@1 10.156 (10.156)
Test: [60/79]	Time 6.051 (5.992)	Loss 2.3026 (2.3026)	Prec@1 14.062 (10.015)
 * Prec@1 10.000
Best Accuracy:78.76
Saving the trained model as: Nov11_retrain_2.th
